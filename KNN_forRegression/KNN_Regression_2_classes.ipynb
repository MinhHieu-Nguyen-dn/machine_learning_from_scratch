{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "I-i5V06j1lB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "MzIVZnz50rwH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Iris dataset"
      ],
      "metadata": {
        "id": "chv3ksVc1nwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "iris_X = iris.data\n",
        "iris_y = iris.target"
      ],
      "metadata": {
        "id": "45HzWn6w1pRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Review 3 classes of the dataset and remove 1"
      ],
      "metadata": {
        "id": "vGLcqec62Pr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of classes: {}; Values: {}'.format(len(np.unique(iris_y)), np.unique(iris_y)))\n",
        "print('Number of data points: {}'.format(len(iris_y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GH714g12TxY",
        "outputId": "3535530d-4603-4e28-e5fb-04da3b08befb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 3; Values: [0 1 2]\n",
            "Number of data points: 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check number of data points from each class\n",
        "X0 = iris_X[iris_y == 0, :]\n",
        "X1 = iris_X[iris_y == 1, :]\n",
        "X2 = iris_X[iris_y == 2, :]\n",
        "\n",
        "print('Class 0: {} data points; Class 1: {} data points; Class 2: {} data points.'.format(len(X0), len(X1), len(X2)))\n",
        "\n",
        "print('For this notebook we use class 0 and class 1 only')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxCwvGdl2hcG",
        "outputId": "dfbc75d6-fe72-4fba-a9e3-fe8d38e47dc9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: 50 data points; Class 1: 50 data points; Class 2: 50 data points.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui8WcupI3yni",
        "outputId": "54a7e60b-c2b2-4704-b761-464c17d17f49"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data to use:"
      ],
      "metadata": {
        "id": "b5RUDIJY4SpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris_X[:100, :]\n",
        "y = iris_y[:100]\n",
        "\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2izrSb0b4RcP",
        "outputId": "67fa90c7-0a34-4c28-b55b-9176de293f87"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 4), (100,))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split datasets and normalize input features"
      ],
      "metadata": {
        "id": "oPS0FmAs5Y0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_features(X):\n",
        "  '''\n",
        "  Normalize the features (each columns) individually.\n",
        "  After this, each column should have mean = 0 and standard deviation = 1.\n",
        "  '''\n",
        "  mean = np.mean(X, axis=0)\n",
        "  std = np.std(X, axis=0)\n",
        "  std[std == 0] = 1e-8 # replace 0 with very small number to avoid division by zero error\n",
        "\n",
        "  X_normalized = (X - mean) / std\n",
        "\n",
        "  return X_normalized"
      ],
      "metadata": {
        "id": "sF3sqc455WFy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(X, y, test_size=0.2):\n",
        "  if X.shape[0] != y.shape[0]:\n",
        "    raise ValueError('X and y must have the same number of samples.')\n",
        "\n",
        "  num_samples = X.shape[0]\n",
        "  test_samples = int(num_samples * test_size)\n",
        "\n",
        "  # Randomly shuffle before sampling\n",
        "  indices = np.arange(num_samples)\n",
        "  np.random.shuffle(indices)\n",
        "\n",
        "  # Split data\n",
        "  X_train = X[indices[:-test_samples]]\n",
        "  X_test = X[indices[-test_samples:]]\n",
        "\n",
        "  y_train = y[indices[:-test_samples]]\n",
        "  y_test = y[indices[-test_samples:]]\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "W6pbIMFq5gAI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = normalize_features(X)"
      ],
      "metadata": {
        "id": "_yECxU2N5kEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "of07LLXd56Pv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calc Euclidean distance between 2 data points"
      ],
      "metadata": {
        "id": "B9R38FeZ0hIY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K5tHF9cyzQv8"
      },
      "outputs": [],
      "source": [
        "def euclidean_dist(p1, p2):\n",
        "  sum_square = np.sum(np.square(p1 - p2))\n",
        "  dist = np.sqrt(sum_square)\n",
        "\n",
        "  return dist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test distance\n",
        "point1 = np.array((1, 2, 3, 7))\n",
        "point2 = np.array((1, 1, 1, 10))\n",
        "\n",
        "print(euclidean_dist(point1, point2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0ju0Wf-1bZ3",
        "outputId": "68053ea2-0d6a-41d6-e518-5b0fbe809118"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7416573867739413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select K nearest neighbors for an instance (data point) based on distance"
      ],
      "metadata": {
        "id": "GbbStlvH7Yzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_k_neighbors(X_train, instance, k=3):\n",
        "  distances = []\n",
        "\n",
        "  for index in range(len(X_train)):\n",
        "    dist = euclidean_dist(X_train[index], instance)\n",
        "    # save distance and index of the data point that has this distance value with input distance\n",
        "    distances.append((dist, index))\n",
        "\n",
        "  distances.sort(key=lambda x: x[0])\n",
        "\n",
        "  k_neighbors = distances[:k]\n",
        "  return k_neighbors"
      ],
      "metadata": {
        "id": "0JLauLYo6DSx"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decide which class a data point (input instance) belongs to based on K nearest neighbors"
      ],
      "metadata": {
        "id": "NiWOoRFw-CLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_class(y_train, k_neighbors):\n",
        "  class_votes = {}\n",
        "\n",
        "  for x in range(len(k_neighbors)):\n",
        "    index = k_neighbors[x][1]\n",
        "    response = y_train[index]\n",
        "\n",
        "    class_votes[response] = class_votes.get(response, 0) + 1\n",
        "\n",
        "  # sort the dict based on its values (count of each class)\n",
        "  sorted_class_votes = sorted(class_votes.items(), key=lambda x: x[1], reverse=True)\n",
        "  most_voted_class = sorted_class_votes[0][0]\n",
        "\n",
        "  return most_voted_class"
      ],
      "metadata": {
        "id": "y1dX4Vl699ig"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to calc accuracy of predictions"
      ],
      "metadata": {
        "id": "pwFk8lr0ATks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def measure_acc(y_test, predictions):\n",
        "  # Ensure y_test and predictions are numpy arrays\n",
        "  if not isinstance(y_test, np.ndarray):\n",
        "      y_test = np.array(y_test)\n",
        "  if not isinstance(predictions, np.ndarray):\n",
        "      predictions = np.array(predictions)\n",
        "\n",
        "  # Check if y_test and predictions have the same shape\n",
        "  if y_test.shape != predictions.shape:\n",
        "      print(\"Error: y_test and predictions must have the same shape.\")\n",
        "\n",
        "  # calc accuracy = percentage of same values count over all values\n",
        "  acc = np.mean(y_test == predictions)\n",
        "\n",
        "  cm = confusion_matrix(y_test, predictions)\n",
        "\n",
        "  return acc, cm"
      ],
      "metadata": {
        "id": "t3KKjLe-AHiX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main code snippet:\n",
        "- Instances are from test set\n",
        "- Data points to calc distance with instances are from train set"
      ],
      "metadata": {
        "id": "8sHH39LSBydR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_list = [3, 5, 7, 9, 11]\n",
        "\n",
        "for k in k_list:\n",
        "  predictions = []\n",
        "  for index in range(len(X_test)):\n",
        "    x_instance = X_test[index]\n",
        "    k_neighbors = select_k_neighbors(X_train, x_instance, k=k)\n",
        "    voted_class = choose_class(y_train, k_neighbors)\n",
        "\n",
        "    predictions.append(voted_class)\n",
        "\n",
        "  accuracy, cm = measure_acc(y_test, predictions)\n",
        "  print('k = {}; acc = {}'.format(k, accuracy))\n",
        "  print('Confusion matrix for k = {}'.format(k))\n",
        "  print(cm, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnDWe1BeA3w2",
        "outputId": "73a660b3-e786-4f17-8b44-cabbfd7e500d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k = 3; acc = 1.0\n",
            "Confusion matrix for k = 3\n",
            "[[ 7  0]\n",
            " [ 0 13]] \n",
            "\n",
            "k = 5; acc = 1.0\n",
            "Confusion matrix for k = 5\n",
            "[[ 7  0]\n",
            " [ 0 13]] \n",
            "\n",
            "k = 7; acc = 1.0\n",
            "Confusion matrix for k = 7\n",
            "[[ 7  0]\n",
            " [ 0 13]] \n",
            "\n",
            "k = 9; acc = 1.0\n",
            "Confusion matrix for k = 9\n",
            "[[ 7  0]\n",
            " [ 0 13]] \n",
            "\n",
            "k = 11; acc = 1.0\n",
            "Confusion matrix for k = 11\n",
            "[[ 7  0]\n",
            " [ 0 13]] \n",
            "\n"
          ]
        }
      ]
    }
  ]
}